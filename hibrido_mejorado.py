# -*- coding: utf-8 -*-
"""Hibrido_Mejorado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vxI3yyGCLCOs0VnCY99mrBjr7hlfeCWh
"""

# ===========================================
# BLOQUE 1 - LIBRERÍAS Y CONFIGURACIÓN
# ===========================================
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D,
    GlobalAveragePooling1D, SpatialDropout1D, Add, GaussianNoise, Concatenate
)
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts
from tensorflow.keras.optimizers import AdamW
from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, matthews_corrcoef
import matplotlib.pyplot as plt

# Semilla fija
np.random.seed(42)
tf.random.set_seed(42)

# ===========================================
# BLOQUE 2 - CARGA DE DATOS
# ===========================================
def cargar_vectorizaciones():
    X_train_tfidf = np.load("/content/X_train_TF_IDF.npy")
    X_val_tfidf = np.load("/content/X_val_TF_IDF.npy")
    X_train_glove = np.load("/content/X_train_glove2vec.npy")
    X_val_glove = np.load("/content/X_val_glove2vec.npy")
    y_train = np.load("/content/y_train_glove2vec.npy")
    y_val = np.load("/content/y_val_glove2vec.npy")

    # Normalización
    X_train_tfidf = X_train_tfidf / (np.linalg.norm(X_train_tfidf, axis=1, keepdims=True) + 1e-8)
    X_val_tfidf = X_val_tfidf / (np.linalg.norm(X_val_tfidf, axis=1, keepdims=True) + 1e-8)
    X_train_glove = X_train_glove / (np.linalg.norm(X_train_glove, axis=1, keepdims=True) + 1e-8)
    X_val_glove = X_val_glove / (np.linalg.norm(X_val_glove, axis=1, keepdims=True) + 1e-8)

    # Redimensionar para CNN
    X_train_glove_cnn = X_train_glove.reshape((X_train_glove.shape[0], X_train_glove.shape[1], 1))
    X_val_glove_cnn = X_val_glove.reshape((X_val_glove.shape[0], X_val_glove.shape[1], 1))

    return X_train_tfidf, X_val_tfidf, X_train_glove_cnn, X_val_glove_cnn, y_train, y_val

# ===========================================
# BLOQUE 3 - MODELO HÍBRIDO OPTIMIZADO
# ===========================================
def crear_modelo_hibrido_optimizado(tfidf_shape, glove_shape, num_classes):
    input_glove = Input(shape=glove_shape)
    x = GaussianNoise(0.1)(input_glove)
    x = Conv1D(256, 7, padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x1 = MaxPooling1D()(x)
    x1 = SpatialDropout1D(0.3)(x1)

    x1_reduced = Conv1D(128, 1, padding='same')(x1)
    x2 = Conv1D(128, 5, padding='same', activation='relu')(x1)
    x2 = BatchNormalization()(x2)
    x2 = Add()([x1_reduced, x2])
    x2 = MaxPooling1D()(x2)
    x2 = SpatialDropout1D(0.3)(x2)

    x2_reduced = Conv1D(64, 1, padding='same')(x2)
    x3 = Conv1D(64, 3, padding='same', activation='relu')(x2)
    x3 = BatchNormalization()(x3)
    x3 = Add()([x2_reduced, x3])
    x3 = GlobalAveragePooling1D()(x3)

    glove_branch = x3

    input_tfidf = Input(shape=(tfidf_shape,))
    y = Dense(128, activation='relu')(input_tfidf)
    y = BatchNormalization()(y)
    y = Dropout(0.4)(y)

    combined = Concatenate()([glove_branch, y])

    z = Dense(256, activation='relu')(combined)
    z = BatchNormalization()(z)
    z = Dropout(0.3)(z)
    z = Dense(128, activation='relu')(z)
    z = BatchNormalization()(z)
    z = Dropout(0.3)(z)

    output = Dense(num_classes, activation='softmax')(z)

    # Solo usar CosineDecayRestarts SIN ReduceLROnPlateau
    lr_schedule = CosineDecayRestarts(initial_learning_rate=0.0005, first_decay_steps=10)
    optimizer = AdamW(learning_rate=lr_schedule)

    model = Model([input_glove, input_tfidf], output)
    model.compile(optimizer=optimizer,
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                  metrics=['accuracy'])
    return model

# ===========================================
# BLOQUE 4 - ENTRENAMIENTO ROBUSTO
# ===========================================
def entrenar_modelo_pro(model, X_train_glove_cnn, X_train_tfidf, y_train, X_val_glove_cnn, X_val_tfidf, y_val):
    callbacks = [
        EarlyStopping(monitor='val_accuracy', patience=12, restore_best_weights=True),
        ModelCheckpoint('mejor_modelo_hibrido_pro.h5', monitor='val_accuracy', save_best_only=True),
        CSVLogger('log_entrenamiento.csv')
    ]
    history = model.fit(
        [X_train_glove_cnn, X_train_tfidf],
        y_train,
        validation_data=([X_val_glove_cnn, X_val_tfidf], y_val),
        epochs=100,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    return history

# ===========================================
# BLOQUE 5 - VISUALIZACIÓN CURVAS APRENDIZAJE
# ===========================================
def visualizar_curvas_aprendizaje(history):
    plt.figure(figsize=(14, 6))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Entrenamiento')
    plt.plot(history.history['val_loss'], label='Validación')
    plt.axvline(np.argmin(history.history['val_loss']), linestyle='--', color='gray', label='Mejor época')
    plt.title('Curva de Pérdida')
    plt.xlabel('Épocas')
    plt.ylabel('Pérdida')
    plt.legend()
    plt.grid(alpha=0.3)

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Validación')
    plt.axvline(np.argmax(history.history['val_accuracy']), linestyle='--', color='gray', label='Mejor época')
    plt.title('Curva de Precisión')
    plt.xlabel('Épocas')
    plt.ylabel('Precisión')
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

# ===========================================
# BLOQUE 6 - EVALUACIÓN AVANZADA
# ===========================================
def evaluar_modelo_pro(model, X_val_glove_cnn, X_val_tfidf, y_val):
    y_pred_probs = model.predict([X_val_glove_cnn, X_val_tfidf])
    y_pred = np.argmax(y_pred_probs, axis=1)

    print("\n📋 Clasificación report:")
    print(classification_report(y_val, y_pred))

    print(f"F1-score macro: {f1_score(y_val, y_pred, average='macro'):.4f}")
    print(f"ROC AUC macro: {roc_auc_score(y_val, y_pred_probs, multi_class='ovo'):.4f}")
    print(f"MCC: {matthews_corrcoef(y_val, y_pred):.4f}")

    cm = confusion_matrix(y_val, y_pred)
    plt.figure(figsize=(8, 6))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap="Blues", xticks_rotation=45)
    plt.title("Matriz de Confusión Profesional")
    plt.tight_layout()
    plt.show()

# ===========================================
# BLOQUE 7 - EJECUCIÓN FINAL
# ===========================================
def main():
    X_train_tfidf, X_val_tfidf, X_train_glove_cnn, X_val_glove_cnn, y_train, y_val = cargar_vectorizaciones()
    model = crear_modelo_hibrido_optimizado(X_train_tfidf.shape[1], X_train_glove_cnn.shape[1:], len(np.unique(y_train)))
    history = entrenar_modelo_pro(model, X_train_glove_cnn, X_train_tfidf, y_train, X_val_glove_cnn, X_val_tfidf, y_val)
    visualizar_curvas_aprendizaje(history)
    evaluar_modelo_pro(model, X_val_glove_cnn, X_val_tfidf, y_val)
    model.save('modelo_hibrido_pro_final.h5')

if __name__ == "__main__":
    main()